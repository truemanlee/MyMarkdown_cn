Title         : DeepVoice3笔记
Author        : Chumin Li
Logo          : True

[TITLE]

# 相关工作

Deep Voice 1 & 2都遵循了传统的TTS架构，分为语素-音素转换模型、发音时间与频率预测模型、语音合成
模型。相反地，Deep Voice 3使用了一个基于注意力机制的seq2seq模型，是更通用的架构。Tacotron与
Char2Wav也是seq2seq的神经TTS模型。跟Taccotron和Char2Wav不同，Deep Voice 3不使用RNN进而加速
训练过程（很奇怪，因为Deep Voice 1的语音合成网络使用了QRNN，训练速度与CNN是差不多的，为何这么说）。
Deep Voic 3建立了一个灵活的基于注意力的产品级TTS模型，而且在准确率中不做妥协，以避免常见的注意力
误差。最后，WaveNet以及SampleRNN是神经声码器模型，但市面上已经高质量的手工特征声码器可以合成高质量
的语音，例如STRAIGHT，Vocaine以及WORLD。Deep Voice 3的设计中没有声码器，但其具有与其他的波形合成
算法结合的可能性（有可能性你怎么不做。。）。Deep Voice 3是目前第一个单模型训练多讲者的TTS模型

# 模型架构

Deep Voice 3架构如下

* 编码器 全卷积编码器，对文本性的特征编码

* 解码器 全卷积因果解码器，多跳注意力卷积网络

* 转换器 全卷积后处理网络，预测最后的声码器参数。转换器并不是因果的，所以可以使用未来信息

误差函数是解码器与转换器的误差的线性组合。对于多讲者，需要输入讲者embedding。

## 文本预处理

文本预处理对效果影响很大。把原始文本数据输入进模型可以得到一个对大部分发音而言可以接受的模型。
然而，一些不常见的单词与重复的单词发音可能会被跳过。通过归一化输入可以缓和以上的问题

1. 将所有字母改为大写（中文不需要）

2. 删除所有标点符号标记

3. 每一个发音结束后都带一个标记（We end every utterance with a period or question mark，不会翻）

4. 每个单词之间的空格替代成特殊的间隔符号，该间隔符号具有讲者读每个单词的停顿时间信息。
我们使用了4种不同的分割(i) 连词（原文slurred-together word，不会翻） (ii) 标准发音
与空格字母 (iii) 两个单词之间短暂的停顿 (iv) 一个长停顿。例如句子"Either way, you should
shoot very slowly,"，在"way"后接了一个长停顿，在"shoot"后接了一个短停顿。

## 字母与音素的联合表达

一个部署的TTS系统应该拥有一套修改发音以便改正常见错误的方法。传统做这件事的方式是建立并维护
一个字典匹配单词与音素级别的表达。

Deep Voice 3直接把字母转化为声音特征，因此也隐性地达到了类似语素-音素的功能。这种隐性的
转换如果发生了错误，是很难被纠正的。因此，除了仅字母输入模型，我们也训练了仅音素输入的模型和混合输入
的模型。这两种模型与仅字母输入模型是不同的，除了偶尔地编码器的输入是音素跟重音的embedding以外。

仅音素输入模型需要进行预处理，把单词转换为音素表达（可以通过字典方式或者训练一个神经网络，Deep
Voice 1不就是这么干的么）。混合输入模型同样也需要类似的预处理，除非单词不在音素字典中。这种不在字典
中的的输入是单词，允许模型使用其隐性的语素-音素表达作为输入。我们发现这提高了发音的准确率以及
降低了注意力误差，特别是在生成比训练集更长的语音时。更重要地，允许使用音素表达的模型可以改正错误发音。

## 卷积模块

