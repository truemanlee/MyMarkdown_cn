Title         : DeepVoice3笔记
Author        : Chumin Li
Logo          : True

[TITLE]

# 相关工作

Deep Voice 1 & 2都遵循了传统的TTS架构，分为语素-音素转换模型、发音时间与频率预测模型、语音合成
模型。相反地，Deep Voice 3使用了一个基于注意力机制的seq2seq模型，是更通用的架构。Tacotron与
Char2Wav也是seq2seq的神经TTS模型。跟Taccotron和Char2Wav不同，Deep Voice 3不使用RNN进而加速
训练过程（很奇怪，因为Deep Voice 1的语音合成网络使用了QRNN，训练速度与CNN是差不多的，为何这么说）。
Deep Voic 3建立了一个灵活的基于注意力的产品级TTS模型，而且在准确率中不做妥协，以避免常见的注意力
误差。最后，WaveNet以及SampleRNN是神经声码器模型，但市面上已经高质量的手工特征声码器可以合成高质量
的语音，例如STRAIGHT，Vocaine以及WORLD。Deep Voice 3的设计中没有声码器，但其具有与其他的波形合成
算法结合的可能性（有可能性你怎么不做。。）。Deep Voice 3是目前第一个单模型训练多讲者的TTS模型

# 模型架构

Deep Voice 3架构如下

* 编码器 全卷积编码器，对文本性的特征编码

* 解码器 全卷积因果解码器，多跳注意力卷积网络

* 转换器 全卷积后处理网络，预测最后的声码器参数。转换器并不是因果的，所以可以使用未来信息

误差函数是解码器与转换器的误差的线性组合。对于多讲者，需要输入讲者embedding。

## 文本预处理

文本预处理对效果影响很大。把原始文本数据输入进模型可以得到一个对大部分发音而言可以接受的模型。
然而，一些不常见的单词与重复的单词发音可能会被跳过。通过归一化输入可以缓和以上的问题

1. 将所有字母改为大写（中文不需要）

2. 删除所有标点符号标记

3. 每一个发音结束后都带一个标记（We end every utterance with a period or question mark，不会翻）

4. 把空格替代成特殊的分割符号，该分割符号具有讲者读每个单词的停顿时间信息。